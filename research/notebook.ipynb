{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from research.utils import load_vocabulary, Tokenizer\n",
    "from research.scorer import Scorer\n",
    "from research.greedy_optimizer import GreedyOptimizer\n",
    "from research.beam_optimizer import BeamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_vocabulary()\n",
    "tokenizer = Tokenizer()\n",
    "scorer = Scorer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation scoring\n",
      "English sentence: I think that machine translation is very interesting subject.\n",
      "Translation from google translate to score: Ich denke, dass maschinelle Übersetzung ein sehr interessantes Thema ist.\n",
      "Log likehood of translation: -7.1561403\n"
     ]
    }
   ],
   "source": [
    "english_sentence = 'I think that machine translation is very interesting subject.'\n",
    "german_translation_from_google = 'Ich denke, dass maschinelle Übersetzung ein sehr interessantes Thema ist.'\n",
    "score = scorer.score_texts(english_sentence, german_translation_from_google)\n",
    "print('Translation scoring')\n",
    "print('English sentence:', english_sentence)\n",
    "print('Translation from google translate to score:', german_translation_from_google)\n",
    "print('Log likehood of translation:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting of next word in translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentence: I think that machine translation is very interesting subject.\n",
      "Unfinished translation: Ich denke, dass maschinelle Übersetzung ein sehr\n",
      "Top 3 next tokens:  ▁interessante ▁interessant ▁Interessant\n"
     ]
    }
   ],
   "source": [
    "unfinished_translation = 'Ich denke, dass maschinelle Übersetzung ein sehr'\n",
    "english_tokens = tokenizer.tokenize(english_sentence)\n",
    "german_tokens = tokenizer.tokenize(unfinished_translation)\n",
    "next_word_probs = scorer.next_word_probabilities([english_tokens], [german_tokens])\n",
    "val, ind = next_word_probs.topk(3)\n",
    "print('English sentence:', english_sentence)\n",
    "print('Unfinished translation:', unfinished_translation )\n",
    "print('Top 3 next tokens: ', vocab.itos[ind[0,0].view(-1)], vocab.itos[ind[0,1].view(-1)], vocab.itos[ind[0,2].view(-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer initialized...\n",
      "English sentence: I think that machine translation is very interesting subject.\n",
      "Translated tokens ▁Ich ▁denke , ▁dass ▁die ▁ maschine lle ▁Übersetzung ▁sehr ▁interessant ▁ist .\n",
      "Log likehood of translation: -6.63\n"
     ]
    }
   ],
   "source": [
    "english_tokens = tokenizer.tokenize(english_sentence)\n",
    "optimizer = GreedyOptimizer(english_sentence)\n",
    "print('Optimizer initialized...')\n",
    "german_tokens = optimizer.optimize()[:-1]\n",
    "score = scorer.score_tokenized_texts([english_tokens], [german_tokens])[0]\n",
    "print('English sentence:', english_sentence)\n",
    "print('Translated tokens', ' '.join(german_tokens))\n",
    "print(f'Log likehood of translation: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer initialized...\n",
      "English sentence: I think that machine translation is very interesting subject.\n",
      "Top 10 translations:\n",
      "1. ▁Ich ▁halte ▁die ▁ maschine lle ▁Übersetzung ▁für ▁ein ▁sehr ▁interessante s ▁Thema . [p = -6.49]\n",
      "2. ▁Ich ▁glaube , ▁dass ▁die ▁ maschine lle ▁Übersetzung ▁sehr ▁interessant ▁ist . [p = -6.54]\n",
      "3. ▁Ich ▁denke , ▁dass ▁die ▁ maschine lle ▁Übersetzung ▁ein ▁sehr ▁interessante s ▁Thema ▁ist . [p = -6.57]\n",
      "4. ▁Ich ▁denke , ▁dass ▁die ▁ maschine lle ▁Übersetzung ▁sehr ▁interessant ▁ist . [p = -6.63]\n",
      "5. ▁Ich ▁glaube , ▁dass ▁die ▁ maschine lle ▁Übersetzung ▁ein ▁sehr ▁interessante s ▁Thema ▁ist . [p = -6.78]\n",
      "6. ▁Ich ▁denke , ▁dass ▁die ▁ maschine lle ▁Übersetzung ▁sehr ▁interessant ▁ist ▁Thema . [p = -6.97]\n",
      "7. ▁Ich ▁denke , ▁dass ▁ maschine lle ▁Übersetzung ▁sehr ▁interessant ▁ist ▁Thema . [p = -7.11]\n",
      "8. ▁Ich ▁denke , ▁dass ▁ maschine lle ▁Übersetzung ▁ein ▁sehr ▁interessante s ▁Thema ▁ist . [p = -7.16]\n",
      "9. ▁Ich ▁glaube , ▁dass ▁ maschine lle ▁Übersetzung ▁sehr ▁interessant ▁ist . [p = -7.60]\n",
      "10. ▁Ich ▁glaube , ▁dass ▁ maschine lle ▁Übersetzung ▁sehr ▁interessant ▁ist ▁Thema . [p = -7.71]\n",
      "Sanity check: log likehood of the best translation = -6.49\n"
     ]
    }
   ],
   "source": [
    "n_beams = 10\n",
    "english_tokens = tokenizer.tokenize(english_sentence)\n",
    "optimizer = BeamOptimizer(english_sentence, n_beams=n_beams)\n",
    "print('Optimizer initialized...')\n",
    "translations, probabilities = optimizer.optimize()\n",
    "print('English sentence:', english_sentence)\n",
    "print('Top', n_beams, 'translations:')\n",
    "for i, translation in enumerate(translations):\n",
    "    print(f\"{i+1}. {' '.join(translation[:-1])} [p = {probabilities[i]:.2f}]\")\n",
    "\n",
    "score = scorer.score_tokenized_texts([english_tokens], [translations[0][:-1]])[0]\n",
    "print(f'Sanity check: log likehood of the best translation = {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
